{
 "unlabeled": {"batch_size": 64, 
     "lr": 0.0001, 
     "pretrain_num_epochs": 500,
     "train_num_epochs": 1000, 
     "alpha": 1.0, 
     "classifier_hidden_dims": [64, 32]
     }, 
 "labeled": {"classifier_hidden_dims": [64, 32], 
     "batch_size": 32, 
     "lr": 0.0001, 
     "train_num_epochs":200,
     "decay_coefficient": 0.1
     }, 

     "encoder_hidden_dims": [512, 256],
     "latent_dim": 64, 
     "drop": 0.1
}